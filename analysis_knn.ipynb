{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 50,
=======
   "execution_count": 2,
>>>>>>> 000a9bb88e7c5bf1fb412196aae531e859531b9d
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from src.knn import KNN_model\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import src.utils as utils\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 51,
=======
   "execution_count": 3,
>>>>>>> 000a9bb88e7c5bf1fb412196aae531e859531b9d
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.knn' from 'c:\\\\Users\\\\musta\\\\OneDrive\\\\Escritorio\\\\machine_learning_project\\\\ml-project-uab\\\\src\\\\knn.py'>"
      ]
     },
<<<<<<< HEAD
     "execution_count": 51,
=======
     "execution_count": 3,
>>>>>>> 000a9bb88e7c5bf1fb412196aae531e859531b9d
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import src.svm_mod\n",
    "importlib.reload(utils)\n",
    "importlib.reload(src.knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without outliers"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 52,
=======
   "execution_count": 24,
>>>>>>> 000a9bb88e7c5bf1fb412196aae531e859531b9d
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/diamonds.csv')\n",
    "X_train, X_test, y_train, y_test = utils.preprocessing_LOS(df)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 53,
=======
   "execution_count": 25,
>>>>>>> 000a9bb88e7c5bf1fb412196aae531e859531b9d
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "0.6536334913112164\n"
=======
      "0.6790975447909754\n"
>>>>>>> 000a9bb88e7c5bf1fb412196aae531e859531b9d
     ]
    }
   ],
   "source": [
    "# Splitting the data into train and validation sets\n",
    "X_train2, X_val, y_train2, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# KNN\n",
<<<<<<< HEAD
    "knn = KNN_model(n_neighbors=5)\n",
=======
    "knn = KNN_model(n_neighbors=5, leaf_size=30)\n",
>>>>>>> 000a9bb88e7c5bf1fb412196aae531e859531b9d
    "knn.fit(X_train2, y_train2)\n",
    "\n",
    "score = knn.score(X_val, y_val)\n",
    "\n",
    "print(score)"
   ]
<<<<<<< HEAD
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value for n_neighbors: 19 with score: 0.6954919102635704\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'n_neighbors': range(1, 20)}  # Set a range for the hyperparameter n_neighbors to try\n",
    "\n",
    "knn = KNN_model(algorithm = 'auto') # Create the model to use for hyperparameter tuning\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5)  # Adjust the cv parameter as needed for cross-validation\n",
    "\n",
    "grid_search.fit(X_train, y_train)  # Fit the hyperparameter search model\n",
    "\n",
    "# Retrieve the best parameter value\n",
    "best_n_neighbors = grid_search.best_params_['n_neighbors']\n",
    "print(\"Best value for n_neighbors:\", best_n_neighbors, \"with score:\", grid_search.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now see how it performs on our validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6972090573986308\n"
     ]
    }
   ],
   "source": [
    "best_model = KNN_model(n_neighbors=best_n_neighbors)\n",
    "best_model.fit(X_train2, y_train2)\n",
    "score = best_model.score(X_val, y_val)\n",
    "print(\"Accuracy:\",score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we increase this accuracy?\n",
    "\n",
    "1. Try to set the parameter `p` (metric used) to 1 so that we apply manhattan since we have somewhat high-dimensional data\n",
    "2. See if changing the `weighting` method has any effect on the accuracy of the model\n",
    "3. Apply a broader range for `n_neighbors` to have more simplicity (reducing overfitting) since our data is high-dimensional\n",
    "\n",
    "For that we'll be applying a randomized search specifying a parameter grid with the mentioned above factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'n_neighbors': 25, 'p': 1, 'weights': 'uniform'}\n",
      "Best score: 0.7002053019138654\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_neighbors': randint(1, 45),  # Range of values for n_neighbors\n",
    "    'weights': ['uniform', 'distance'],  # Weighting method\n",
    "    'p': [1, 2]  # Power parameter for Minkowski distance (1 for Manhattan, 2 for Euclidean)\n",
    "}\n",
    "\n",
    "knn = KNN_model(algorithm = 'auto') # Create the model to use for hyperparameter tuning\n",
    "knn_random = RandomizedSearchCV(knn, param_distributions=param_grid, n_iter = 30, cv = 5, random_state = 42)  # Define the random search model\n",
    "knn_random.fit(X_train, y_train)  # Fit the random search model\n",
    "\n",
    "# Retrieve the best hyperparameters\n",
    "best_params = knn_random.best_params_\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "\n",
    "best_score = knn_random.best_score_\n",
    "print(\"Best score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6969457609268036\n"
     ]
    }
   ],
   "source": [
    "knn = KNN_model(**best_params)  # Create a new model with the best parameters\n",
    "knn.fit(X_train2, y_train2)  # Fit this model to the data\n",
    "score = knn.score(X_val, y_val)  # Calculate the accuracy score\n",
    "print(\"Accuracy:\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning beyond just `n_neighbors` doesn't seem to have a large increment to the accuracy in our model."
   ]
=======
>>>>>>> 000a9bb88e7c5bf1fb412196aae531e859531b9d
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
